## Week 2:
- Designed structure of project
- Created necessary classes
- Built ReLU function within non-linearity class and necessary tests

## Week 3:
- Wrote functions for the main class of the network such as calling convolutional function, padding function etc.
- Wrote tests for functions


## Week 4:
- Convolutions work, pooling works 
- Started with softmax, loss functions and calculating gradients
- Fully connected layer created, has one weight-matrix